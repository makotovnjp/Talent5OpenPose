{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tạo Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mục tiêu\n",
    "\n",
    "1.\tHiểu và lập trình được Feature Model\n",
    "2.\tHiểu và lập trình được Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPoseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OpenPoseNet, self).__init__()\n",
    "\n",
    "        # Feature Model\n",
    "        self.model0 = OpenPose_Feature()\n",
    "\n",
    "        # Stage Model\n",
    "        self.model1_1 = make_OpenPose_block('block1_1')\n",
    "        self.model2_1 = make_OpenPose_block('block2_1')\n",
    "        self.model3_1 = make_OpenPose_block('block3_1')\n",
    "        self.model4_1 = make_OpenPose_block('block4_1')\n",
    "        self.model5_1 = make_OpenPose_block('block5_1')\n",
    "        self.model6_1 = make_OpenPose_block('block6_1')\n",
    "\n",
    "        # confidence heatmap\n",
    "        self.model1_2 = make_OpenPose_block('block1_2')\n",
    "        self.model2_2 = make_OpenPose_block('block2_2')\n",
    "        self.model3_2 = make_OpenPose_block('block3_2')\n",
    "        self.model4_2 = make_OpenPose_block('block4_2')\n",
    "        self.model5_2 = make_OpenPose_block('block5_2')\n",
    "        self.model6_2 = make_OpenPose_block('block6_2')\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"forward\")\n",
    "        # Feature Module\n",
    "        out1 = self.model0(x)\n",
    "\n",
    "        # Stage1\n",
    "        out1_1 = self.model1_1(out1)  # PAFs\n",
    "        out1_2 = self.model1_2(out1)  # confidence heatmap\n",
    "\n",
    "        # CStage2\n",
    "        out2 = torch.cat([out1_1, out1_2, out1], 1)  # Kết hợp các channel\n",
    "        out2_1 = self.model2_1(out2)\n",
    "        out2_2 = self.model2_2(out2)\n",
    "\n",
    "        # Stage3\n",
    "        out3 = torch.cat([out2_1, out2_2, out1], 1)\n",
    "        out3_1 = self.model3_1(out3)\n",
    "        out3_2 = self.model3_2(out3)\n",
    "\n",
    "        # Stage4\n",
    "        out4 = torch.cat([out3_1, out3_2, out1], 1)\n",
    "        out4_1 = self.model4_1(out4)\n",
    "        out4_2 = self.model4_2(out4)\n",
    "\n",
    "        # Stage5\n",
    "        out5 = torch.cat([out4_1, out4_2, out1], 1)\n",
    "        out5_1 = self.model5_1(out5)\n",
    "        out5_2 = self.model5_2(out5)\n",
    "\n",
    "        # Stage6\n",
    "        out6 = torch.cat([out5_1, out5_2, out1], 1)\n",
    "        out6_1 = self.model6_1(out6)\n",
    "        out6_2 = self.model6_2(out6)\n",
    "\n",
    "        # lưu các thông tin loss\n",
    "        saved_for_loss = []\n",
    "        saved_for_loss.append(out1_1)  # PAFs\n",
    "        saved_for_loss.append(out1_2)  # confidence heatmap\n",
    "        saved_for_loss.append(out2_1)\n",
    "        saved_for_loss.append(out2_2)\n",
    "        saved_for_loss.append(out3_1)\n",
    "        saved_for_loss.append(out3_2)\n",
    "        saved_for_loss.append(out4_1)\n",
    "        saved_for_loss.append(out4_2)\n",
    "        saved_for_loss.append(out5_1)\n",
    "        saved_for_loss.append(out5_2)\n",
    "        saved_for_loss.append(out6_1)\n",
    "        saved_for_loss.append(out6_2)\n",
    "\n",
    "\n",
    "        return (out6_1, out6_2), saved_for_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPose_Feature(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OpenPose_Feature, self).__init__()\n",
    "\n",
    "        # dùng 1 phần model VGG-19 cho block đầu tiên\n",
    "        vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "        model = {}\n",
    "        model['block0'] = vgg19.features[0:23]  # VGG19の最初の10個の畳み込み層まで\n",
    "\n",
    "        # cho thêm vào block0 2 layer Convolution và 1 layer ReLU\n",
    "        model['block0'].add_module(\"23\", torch.nn.Conv2d(\n",
    "            512, 256, kernel_size=3, stride=1, padding=1))\n",
    "        model['block0'].add_module(\"24\", torch.nn.ReLU(inplace=True))\n",
    "        model['block0'].add_module(\"25\", torch.nn.Conv2d(\n",
    "            256, 128, kernel_size=3, stride=1, padding=1))\n",
    "        model['block0'].add_module(\"26\", torch.nn.ReLU(inplace=True))\n",
    "\n",
    "        self.model = model['block0']\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.model(x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_OpenPose_block(block_name):\n",
    "\n",
    "    blocks = {}\n",
    "    # Stage 1\n",
    "    blocks['block1_1'] = [{'conv5_1_CPM_L1': [128, 128, 3, 1, 1]},\n",
    "                          {'conv5_2_CPM_L1': [128, 128, 3, 1, 1]},\n",
    "                          {'conv5_3_CPM_L1': [128, 128, 3, 1, 1]},\n",
    "                          {'conv5_4_CPM_L1': [128, 512, 1, 1, 0]},\n",
    "                          {'conv5_5_CPM_L1': [512, 38, 1, 1, 0]}]\n",
    "\n",
    "    blocks['block1_2'] = [{'conv5_1_CPM_L2': [128, 128, 3, 1, 1]},\n",
    "                          {'conv5_2_CPM_L2': [128, 128, 3, 1, 1]},\n",
    "                          {'conv5_3_CPM_L2': [128, 128, 3, 1, 1]},\n",
    "                          {'conv5_4_CPM_L2': [128, 512, 1, 1, 0]},\n",
    "                          {'conv5_5_CPM_L2': [512, 19, 1, 1, 0]}]\n",
    "\n",
    "    # Stages 2 - 6\n",
    "    for i in range(2, 7):\n",
    "        blocks['block%d_1' % i] = [\n",
    "            {'Mconv1_stage%d_L1' % i: [185, 128, 7, 1, 3]},\n",
    "            {'Mconv2_stage%d_L1' % i: [128, 128, 7, 1, 3]},\n",
    "            {'Mconv3_stage%d_L1' % i: [128, 128, 7, 1, 3]},\n",
    "            {'Mconv4_stage%d_L1' % i: [128, 128, 7, 1, 3]},\n",
    "            {'Mconv5_stage%d_L1' % i: [128, 128, 7, 1, 3]},\n",
    "            {'Mconv6_stage%d_L1' % i: [128, 128, 1, 1, 0]},\n",
    "            {'Mconv7_stage%d_L1' % i: [128, 38, 1, 1, 0]}\n",
    "        ]\n",
    "\n",
    "        blocks['block%d_2' % i] = [\n",
    "            {'Mconv1_stage%d_L2' % i: [185, 128, 7, 1, 3]},\n",
    "            {'Mconv2_stage%d_L2' % i: [128, 128, 7, 1, 3]},\n",
    "            {'Mconv3_stage%d_L2' % i: [128, 128, 7, 1, 3]},\n",
    "            {'Mconv4_stage%d_L2' % i: [128, 128, 7, 1, 3]},\n",
    "            {'Mconv5_stage%d_L2' % i: [128, 128, 7, 1, 3]},\n",
    "            {'Mconv6_stage%d_L2' % i: [128, 128, 1, 1, 0]},\n",
    "            {'Mconv7_stage%d_L2' % i: [128, 19, 1, 1, 0]}\n",
    "        ]\n",
    "\n",
    "    # configuration data\n",
    "    cfg_dict = blocks[block_name]\n",
    "\n",
    "    # 2. triển khai nội dung configuration sang layers\n",
    "    layers = []\n",
    "\n",
    "    for i in range(len(cfg_dict)):\n",
    "        for k, v in cfg_dict[i].items():\n",
    "            if 'pool' in k:\n",
    "                layers += [nn.MaxPool2d(kernel_size=v[0], stride=v[1],\n",
    "                                        padding=v[2])]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels=v[0], out_channels=v[1],\n",
    "                                   kernel_size=v[2], stride=v[3],\n",
    "                                   padding=v[4])\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "\n",
    "    # chuyển layers sang Sequential\n",
    "    net = nn.Sequential(*layers[:-1])\n",
    "\n",
    "    # Init weights\n",
    "    def _initialize_weights_norm(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.normal_(m.weight, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0.0)\n",
    "\n",
    "    net.apply(_initialize_weights_norm)\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "net = OpenPoseNet()\n",
    "net.train()\n",
    "\n",
    "# Dummy data\n",
    "batch_size = 2\n",
    "dummy_img = torch.rand(batch_size, 3, 368, 368)\n",
    "\n",
    "# Test\n",
    "outputs = net(dummy_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
